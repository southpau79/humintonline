{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fce0555bf0dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'darkgrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style = 'darkgrid')\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "from IPython.display import HTML, display\n",
    "from IPython.core import display as ICD\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#init_notebook_mode(connected=True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the column description and ensure you understand each attribute well\n",
    "data = pd.read_csv('Bank_Personal_Loan_Modelling.csv')\n",
    "data.columns = [\"ID\",\"Age\",\"Experience\",\"Income\",\"ZIPCode\",\"Family\",\"CCAvg\",\"Education\",\"Mortgage\",\"PersonalLoan\",\"SecuritiesAccount\",\"CDAccount\",\"Online\",\"CreditCard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether any column has null values\n",
    "data.apply(lambda x : sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View and understand the data\n",
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the unique data\n",
    "data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people with Zero Mortgage\n",
    "data[data['Mortgage'] < 1]['Mortgage'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people with Zero Credit Card Spending per month\n",
    "data[data['CreditCard'] < 1]['CreditCard'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the relation between each columns\n",
    "sns.pairplot(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot()\n",
    "sns.pairplot(data.iloc[:,1:].sample(100),diag_kind='kde', hue=\"PersonalLoan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observations:\n",
    "# Age feature is normally distributed with majority of customers falling between 30 years and 60 years of age. We can confirm this by looking at the describe statement above, which shows mean is almost equal to median\n",
    "# Experience is normally distributed with more customer having experience starting from 8 years. Here the mean is equal to median. There are negative values in the Experience. This could be a data input error as in general it is not possible to measure negative years of experience. We can delete these values, because we have 3 or 4 records from the sample.\n",
    "# Income is positively skewed. Majority of the customers have income between 45K and 55K. We can confirm this by saying the mean is greater than the median\n",
    "# CCAvg is also a positively skewed variable and average spending is between 0K to 10K and majority spends less than 2.5K\n",
    "# Mortgage 70% of the individuals have a mortgage of less than 40K. However the max value is 635K\n",
    "# The variables family and education are ordinal variables. The distribution of families is evenly distributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found some negative values on Experience column\n",
    "data[data['Experience'] < 0]['Experience'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the negative variable\n",
    "dfExp = data.loc[data['Experience'] >0]\n",
    "negExp = data.Experience < 0\n",
    "column_name = 'Experience'\n",
    "mylist = data.loc[negExp]['ID'].tolist() # getting the customer ID who has negative experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negExp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in mylist:\n",
    "    age = data.loc[np.where(data['ID']==id)][\"Age\"].tolist()[0]\n",
    "    education = data.loc[np.where(data['ID']==id)][\"Education\"].tolist()[0]\n",
    "    df_filtered = dfExp[(dfExp.Age == age) & (dfExp.Education == education)]\n",
    "    exp = df_filtered['Experience'].median()\n",
    "    data.loc[data.loc[np.where(data['ID']==id)].index, 'Experience'] = exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Experience'] < 0]['Experience'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the target column is PersonalLoan\n",
    "sns.boxplot(x='Education',y='Income',hue='PersonalLoan',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation : It seems the customers whose education level is 1 is having more income. \n",
    "# However customers who have taken the personal loan have the same income levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Education\", y='Mortgage', hue=\"PersonalLoan\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference : The customers who have personal loan have high mortgage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"SecuritiesAccount\", data=data,hue=\"PersonalLoan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Family',data=data,hue='PersonalLoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations - Family size does not have any impact in personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {1:'red',2:'yellow',3:'green'}\n",
    "plt.scatter(data['Experience'],data['Age'],c=data['Education'].apply(lambda x:colors[x]))\n",
    "plt.xlabel('Experience')\n",
    "plt.ylabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above plot shows that experinece and age are having positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr().abs(), vmax=.8, square=True, fmt='.2f', annot=True, linecolor='white', linewidths=0.01, cmap='coolwarm')\n",
    "plt.title('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above correlation chart, we can observe that\n",
    "# Correlation between Age and Experience is 0.99.\n",
    "# Correlation between Income and CCAvg is 0.65.\n",
    "# These are the pairs of features having high correlation i.e (>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='CDAccount',data=data,hue='PersonalLoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation: Customers who does not have CD account , does not have loan as well. This seems to be majority. But almost all customers who has CD account have loan as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data.Family,y=data.Income,hue=data.PersonalLoan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation - Families with income less than 100K are less likely to take loan than families with high income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of each feature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = data.copy(deep=True)\n",
    "f, axes = plt.subplots(4, 3, figsize=(15, 10), sharex=True)\n",
    "sns.distplot(features[\"Age\"], rug=False, color=\"skyblue\", ax=axes[0, 0])\n",
    "sns.distplot(features[\"Experience\"], rug=False, color=\"olive\", ax=axes[0, 1])\n",
    "sns.distplot(features[\"Income\"], rug=False, color=\"gold\", ax=axes[0, 2])\n",
    "sns.distplot(features[\"Family\"], rug=False, color=\"teal\", ax=axes[1, 0])\n",
    "sns.distplot(features[\"CCAvg\"], rug=False, ax=axes[1, 1])\n",
    "sns.distplot(features[\"Education\"], rug=False, color=\"red\", ax=axes[1, 2])\n",
    "sns.distplot(features[\"Mortgage\"], rug=False, color=\"skyblue\", ax=axes[2, 0])\n",
    "sns.distplot(features[\"SecuritiesAccount\"], rug=False, color=\"olive\", ax=axes[2, 1])\n",
    "sns.distplot(features[\"CDAccount\"], rug=False, color=\"gold\", ax=axes[2, 2])\n",
    "sns.distplot(features[\"Online\"], rug=False, color=\"teal\", ax=axes[3, 0])\n",
    "sns.distplot(features[\"CreditCard\"], rug=False, ax=axes[3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data.drop(['ID','Experience'], axis=1), test_size=0.3 , random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_set.pop('PersonalLoan')\n",
    "test_labels = test_set.pop('PersonalLoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#train_set, test_set, train_labels, test_labels = train_test_split(X, Y, test_size=0.30, random_state=1)\n",
    "\n",
    "# Invoking the NB Gaussian function to create the model\n",
    "# fitting the model in the training data set\n",
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(train_set, train_labels)\n",
    "\n",
    "model_gnb.score(train_set , train_labels)      # performance on test data\n",
    "\n",
    "test_pred = model_gnb.predict(test_set)\n",
    "\n",
    "print(metrics.classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "y_predict_gnb = model_gnb.predict(test_set)\n",
    "gnb_acc=metrics.accuracy_score(test_labels,y_predict_gnb)\n",
    "print(\"Naive Bayes Accuracy is: \", gnb_acc)\n",
    "print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "scores = cross_val_score(model_gnb, train_set, train_labels, cv=10)\n",
    "print(\"Cross-validated scores:\", scores , scores)\n",
    "print(\"Average score:\" , np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression(solver='lbfgs' , max_iter=5000 , multi_class='multinomial')\n",
    "model_lr.fit(train_set, train_labels)\n",
    "\n",
    "model_lr.score(train_set , train_labels)      # performance on test data\n",
    "test_pred = model_lr.predict(test_set)\n",
    "\n",
    "print(metrics.classification_report(test_labels, test_pred))\n",
    "\n",
    "lr_acc=metrics.accuracy_score(test_labels,y_predict_gnb)\n",
    "print(\"Logistic Regression Accuracy is: \", lr_acc)\n",
    "\n",
    "print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "scores = cross_val_score(model_lr, train_set, train_labels, cv=10)\n",
    "print(\"Cross-validated scores:\", scores , scores)\n",
    "print(\"Average score:\" , np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression score:\" , model_lr.score(train_set , train_labels))\n",
    "print(\"Nave Bayes score:\" , model_gnb.score(train_set , train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here Logistic Regression model seems like have the highest accuracy and we can choose that as our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models\n",
    "X=data.drop(['PersonalLoan','Experience','ID'],axis=1)\n",
    "y=data.pop('PersonalLoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=12345)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here Logistic Regression model seems like have the highest accuracy and we can choose that as our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = data.drop(['ID','ZIPCode','PersonalLoan'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = data['PersonalLoan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(10, 100, 10),\n",
    "    'min_samples_split': range(10, 100, 10),\n",
    "    'criterion': [\"entropy\", \"gini\"]\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "                          cv = n_folds, verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the decision tree with best hyperparameters\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=10,criterion='gini',min_samples_leaf=10,min_samples_split=60)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = model.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_jobs=-1)\n",
    "param={'n_neighbors':np.arange(1,50),'weights':['uniform','distance']}\n",
    "GS=GridSearchCV(knn,param,cv=5,scoring='recall')\n",
    "GS.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update and redifine your knn model\n",
    "KNN=KNeighborsClassifier(n_neighbors=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR_bag=BaggingClassifier(base_estimator=LR,n_estimators=25,random_state=0,n_jobs=-1)\n",
    "NB_bag=BaggingClassifier(base_estimator=NB,n_estimators=24,random_state=0,n_jobs=-1)\n",
    "KNN_bag=BaggingClassifier(base_estimator=KNN,n_estimators=80,random_state=0,n_jobs=-1)\n",
    "DT_reg=DecisionTreeClassifier(max_depth=10,criterion='gini',min_samples_leaf=10,min_samples_split=60)\n",
    "DT_bag=BaggingClassifier(n_estimators=10,random_state=0,n_jobs=-1)\n",
    "RF=RandomForestClassifier(n_estimators=130,criterion='entropy',random_state=0,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "kf=KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "for model, name in zip([LR,LR_bag,NB,NB_bag,KNN,KNN_bag,DT_reg,DT_bag,RF], \n",
    "      ['LR','BaggedLR','NB','BaggedNB','KNN','BaggedKNN','DT_Reg','BaggedDT','RF']):\n",
    "    roc_auc=[]\n",
    "    for train,test in kf.split(X,y):\n",
    "        Xtrain,Xtest=X[train,:],X[test,:]\n",
    "        Ytrain,Ytest=y[train],y[test]\n",
    "        model.fit(Xtrain,Ytrain)\n",
    "        Y_predict=model.predict(Xtest)\n",
    "        #cm=metrics.confusion_matrix(Ytest,Y_predict)\n",
    "        fpr,tpr, _ = roc_curve(Ytest,Y_predict)\n",
    "        roc_auc.append(auc(fpr, tpr))\n",
    "    print(\"AUC scores: %0.02f (+/- %0.5f) [%s]\" % (np.mean(roc_auc),\n",
    "                                    np.var(roc_auc,ddof=1), name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting models\n",
    "LR_boost=AdaBoostClassifier(base_estimator=LR,n_estimators=170)\n",
    "NB_boost=AdaBoostClassifier(base_estimator=NB,n_estimators=350)\n",
    "RF_boost=AdaBoostClassifier(base_estimator=RF,n_estimators=100)\n",
    "DT_boost=AdaBoostClassifier(n_estimators=100)\n",
    "GB_boost=GradientBoostingClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Model\n",
    "stacked = VotingClassifier(estimators = [('Bagged_LR',LR_bag),('BoostedRF', RF_boost), ('GBoost', GB_boost)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "kf=KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "for model, name in zip([LR,LR_boost,NB,NB_boost,DT_boost,RF,RF_boost,GB_boost,stacked], \n",
    "      ['LR','BoostedLR','NB','BoostedNB','BoostedDT','RF','BoostedRF','GradientBoost','stacked']):\n",
    "    roc_auc=[]\n",
    "    for train,test in kf.split(X,y):\n",
    "        Xtrain,Xtest=X[train,:],X[test,:]\n",
    "        Ytrain,Ytest=y[train],y[test]\n",
    "        model.fit(Xtrain,Ytrain)\n",
    "        Y_predict=model.predict(Xtest)\n",
    "        #cm=metrics.confusion_matrix(Ytest,Y_predict)\n",
    "        fpr,tpr, _ = roc_curve(Ytest,Y_predict)\n",
    "        roc_auc.append(auc(fpr, tpr))\n",
    "    print(\"AUC scores: %0.02f (+/- %0.5f) [%s]\" % (np.mean(roc_auc),\n",
    "                                    np.var(roc_auc,ddof=1), name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "# From the above model, we can clearly infer Gradient Boosting followed by Boosted Random forest performs better with respect to AUC as well as Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall understanding:\n",
    "\n",
    "# Age feature is normally distributed with majority of customers falling between 30 years and 60 years of age \n",
    "# Experience is normally distributed with more customer having experience starting from 8 years \n",
    "# Income is positively skewed. Majority of the customers have income between 45K and 55K \n",
    "# CCAvg is also a positively skewed variable and average spending is between 0K to 10K and majority spends less than 2.5K\n",
    "# Mortgage 70% of the individuals have a mortgage of less than 40K. However the max value is 635K\n",
    "# The variables family and education are ordinal variables. The distribution of families is evenly distributed\n",
    "# It seems the customers whose education level is 1 is having more income. \n",
    "# However customers who have taken the personal loan have the same income levels\n",
    "# The customers who have personal loan have high mortgage\n",
    "# Family size does not have any impact in personal loan\n",
    "# Experinece and age are having positive correlation\n",
    "# Correlation between Age and Experience is 0.99\n",
    "# Correlation between Income and CCAvg is 0.65\n",
    "# Customers who do not have CD account, do not have loan as well and almost all customers who have CD account have loan as well\n",
    "# Families with income less than 100K are less likely to take loan than families with high income\n",
    "# Logistic Regression has higher accuracy than other models\n",
    "# The LR Model can be boosted using Gradient Boosting and Boosted Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign Model for Personal Loan: \n",
    "\n",
    "# Target customers aged between 30-60 years with 8+ years of experience having income between 45k-55k preferably having a credit card and existing mortgage. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
